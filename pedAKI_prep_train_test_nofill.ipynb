{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script creates the final train/test X and y for AdaBoost in *.mat files\n",
    "* Set db_name variabele accordingly before running this script. db_name$\\in${'ism', 'stm', 'banner'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pedAKI_predictor as ppaki\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import signal, stats, io\n",
    "import stm_utilities as stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name = 'ism'\n",
    "fileDir = os.path.dirname(\"__file__\")\n",
    "cut_off = 0\n",
    "fill_mode = 'no_fill'\n",
    "ref_type = 'onset'\n",
    "test_size = 0.3\n",
    "cv = 5\n",
    "\n",
    "timelag_all = list(-1*np.arange(25))\n",
    "timewin_all = [12, 6]\n",
    "\n",
    "combination = [(x,y) for x in timelag_all for y in timewin_all]\n",
    "mask = [abs(x)>=abs(y) for (x,y) in combination]\n",
    "combination = list(itertools.compress(combination,mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ISM train-test data set (no filling NaN values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if db_name=='ism':\n",
    "    reload(ppaki)\n",
    "    # dirFrom_ism = 'io_ism5'\n",
    "    # dirTo_ism = 'train_test_ism7_nofill_only_level'\n",
    "    dirFrom_ism = 'io_ism3'\n",
    "    dirTo_ism = 'train_test_ism_nofill'\n",
    "\n",
    "    if not os.path.exists(os.path.join(fileDir, dirTo_ism)):\n",
    "        os.makedirs(os.path.join(fileDir, dirTo_ism))\n",
    "\n",
    "    # ceid_group_ism = pickle.load(open(os.path.join(fileDir, 'io_ism5', 'ceid_group_ism.pkl'), 'rb'))\n",
    "    # only_level = True\n",
    "    # only_rate = False\n",
    "\n",
    "    for tlag, twin in np.abs(combination):\n",
    "\n",
    "    #     Check if test-train files exist\n",
    "        fname_tt_pkl = \"ism_onset_tt_tlag{:03d}_twin{:03d}.pkl\".format(tlag, twin)\n",
    "        fname_tt_pkl = os.path.join(fileDir, dirTo_ism, fname_tt_pkl)\n",
    "        fname_tt_mat = 'ism_onset_tt_tlag{:03d}_twin{:03d}.mat'.format(tlag, twin)\n",
    "        fname_tt_mat = os.path.join(fileDir, dirTo_ism, fname_tt_mat)\n",
    "\n",
    "        if os.path.isfile(fname_tt_pkl) and os.path.isfile(fname_tt_mat):\n",
    "            pass\n",
    "        else:\n",
    "    #         try:\n",
    "            fname_aki = \"ism_onset_io_tlag{:03d}_twin{:03d}_aki.pkl\".format(tlag, twin)\n",
    "            fname_con = \"ism_onset_io_tlag{:03d}_twin{:03d}_con.pkl\".format(tlag, twin)\n",
    "            fname_aki = os.path.join(fileDir, dirFrom_ism, fname_aki)\n",
    "            fname_con = os.path.join(fileDir, dirFrom_ism, fname_con)\n",
    "            io_mat_aki = pd.read_pickle(fname_aki)\n",
    "    #         if only_level:\n",
    "    #             io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_ism['ceidAKILevel']), :]\n",
    "    #         elif only_rate:\n",
    "    #             io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_ism['ceidAKIRate']), :]\n",
    "\n",
    "            io_mat_con = pd.read_pickle(fname_con)\n",
    "            io_mat = pd.concat([io_mat_aki, io_mat_con], axis=0)\n",
    "\n",
    "            lr_pred = ppaki.AKI_predictor_log(io_mat, False, cutoff=cut_off, fill_mode=fill_mode, ref_type=ref_type, cv=cv, \n",
    "                                                      timelag=tlag, timewindow=twin, do_balance=False)\n",
    "\n",
    "            X_train = lr_pred.X_train.as_matrix()\n",
    "            y_train = lr_pred.y_train\n",
    "            X_test = lr_pred.X_test.as_matrix()\n",
    "            y_test = lr_pred.y_test\n",
    "            predictors = lr_pred.cols\n",
    "\n",
    "            f = open(fname_tt_pkl, 'wb')\n",
    "            pickle.dump({'X_train': X_train, \n",
    "                         'y_train': y_train, \n",
    "                         'X_test': X_test,\n",
    "                         'y_test': y_test, \n",
    "                         'predictors': predictors}, f)\n",
    "            f.close()\n",
    "\n",
    "            io.savemat(fname_tt_mat, {'X_train':X_train, 'y_train': y_train, \n",
    "                                   'X_test': X_test, 'y_test': y_test, \n",
    "                                   'predictors': predictors})\n",
    "    #         except:\n",
    "    #             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create STM train-test data set (no filling NaN values)\n",
    "> UOMs of lactic_acid, creatinine, glucose, albumin are converted to be consistent with those of  ISM UOMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if db_name=='stm'\n",
    "    dirFrom_stm = 'io_stm3'\n",
    "    dirTo_stm = 'train_test_stm_nofill'\n",
    "    if not os.path.exists(os.path.join(fileDir, dirTo_stm)):\n",
    "        os.makedirs(os.path.join(fileDir, dirTo_stm))\n",
    "\n",
    "    # ceid_group_stm = pickle.load(open(os.path.join(fileDir, 'io_stm5', 'ceid_group_stm.pkl'), 'rb'))\n",
    "    # only_level = True\n",
    "    # only_rate = False\n",
    "\n",
    "    for tlag, twin in np.abs(combination):\n",
    "\n",
    "    #     Check if test-train files exist\n",
    "        fname_tt_pkl = \"stm_onset_tt_tlag{:03d}_twin{:03d}.pkl\".format(tlag, twin)\n",
    "        fname_tt_pkl = os.path.join(fileDir, dirTo_stm, fname_tt_pkl)\n",
    "        fname_tt_mat = 'stm_onset_tt_tlag{:03d}_twin{:03d}.mat'.format(tlag, twin)\n",
    "        fname_tt_mat = os.path.join(fileDir, dirTo_stm, fname_tt_mat)\n",
    "\n",
    "    #     if os.path.isfile(fname_tt_pkl) and os.path.isfile(fname_tt_mat):\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         try:\n",
    "        fname_aki = \"stm_onset_io_tlag{:03d}_twin{:03d}_aki.pkl\".format(tlag, twin)\n",
    "        fname_con = \"stm_onset_io_tlag{:03d}_twin{:03d}_con.pkl\".format(tlag, twin)\n",
    "        fname_aki = os.path.join(fileDir, dirFrom_stm, fname_aki)\n",
    "        fname_con = os.path.join(fileDir, dirFrom_stm, fname_con)\n",
    "        io_mat_aki = pd.read_pickle(fname_aki)\n",
    "    #     if only_level:\n",
    "    #         io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_stm['ceidAKILevel']), :]\n",
    "    #     elif only_rate:\n",
    "    #         io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_stm['ceidAKIRate']), :]\n",
    "\n",
    "        io_mat_con = pd.read_pickle(fname_con)\n",
    "        io_mat = pd.concat([io_mat_aki, io_mat_con], axis=0)\n",
    "        for ft in io_mat.columns:\n",
    "            if 'lactic_acid' in ft:\n",
    "                io_mat[ft] = io_mat[ft]*9.009        \n",
    "            #     elif 'creatinine' in ft:\n",
    "            #         _io_onset[ft] = _io_onset[ft]*0.01131\n",
    "            elif 'glucose' in ft:\n",
    "                io_mat[ft] = io_mat[ft]*18.0182\n",
    "            elif 'albumin' in ft:\n",
    "                io_mat[ft] = io_mat[ft]*0.1\n",
    "\n",
    "\n",
    "\n",
    "    #             io_mat = stm.uomConvert('stm', 'ism', io_mat)\n",
    "\n",
    "        lr_pred = ppaki.AKI_predictor_log(io_mat, ready=False, cutoff=cut_off, fill_mode=fill_mode, \n",
    "                                          ref_type=ref_type, cv=cv, \n",
    "                                          timelag=tlag, timewindow=twin, do_balance=False)\n",
    "\n",
    "        X_train = lr_pred.X_train.as_matrix()\n",
    "        y_train = lr_pred.y_train\n",
    "        X_test = lr_pred.X_test.as_matrix()\n",
    "        y_test = lr_pred.y_test\n",
    "        predictors = lr_pred.cols        \n",
    "\n",
    "        f = open(fname_tt_pkl, 'wb')\n",
    "        pickle.dump({'X_train': X_train, \n",
    "                     'y_train': y_train, \n",
    "                     'X_test': X_test,\n",
    "                     'y_test': y_test, \n",
    "                     'predictors': predictors}, f)\n",
    "        f.close()\n",
    "\n",
    "        io.savemat(fname_tt_mat, {'X_train':X_train, 'y_train': y_train, \n",
    "                                  'X_test': X_test, 'y_test': y_test, \n",
    "                                  'predictors': predictors})\n",
    "    #         except:\n",
    "    #             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Banner train-test data set (no filling NaN values)\n",
    "> UOMs of lactic_acid is converted to be consistent with that of ISM UOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2a4cb325b0c9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2a4cb325b0c9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    if db_name=='banner'\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if db_name=='banner'\n",
    "    dirFrom_banner = 'io_banner3'\n",
    "    dirTo_banner = 'train_test_banner_nofill'\n",
    "    # ceid_group_stm = pickle.load(open(os.path.join(fileDir, 'io_stm5', 'ceid_group_stm.pkl'), 'rb'))\n",
    "    # only_level = True\n",
    "    # only_rate = False\n",
    "    if not os.path.exists(os.path.join(fileDir, dirTo_banner)):\n",
    "        os.makedirs(os.path.join(fileDir, dirTo_banner))\n",
    "\n",
    "    for tlag, twin in np.abs(combination):\n",
    "\n",
    "    #     Check if test-train files exist\n",
    "        fname_tt_pkl = \"banner_onset_tt_tlag{:03d}_twin{:03d}.pkl\".format(tlag, twin)\n",
    "        fname_tt_pkl = os.path.join(fileDir, dirTo_banner, fname_tt_pkl)\n",
    "        fname_tt_mat = 'banner_onset_tt_tlag{:03d}_twin{:03d}.mat'.format(tlag, twin)\n",
    "        fname_tt_mat = os.path.join(fileDir, dirTo_banner, fname_tt_mat)\n",
    "\n",
    "    #     if os.path.isfile(fname_tt_pkl) and os.path.isfile(fname_tt_mat):\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         try:\n",
    "        fname_aki = \"banner_onset_io_tlag{:03d}_twin{:03d}_aki.pkl\".format(tlag, twin)\n",
    "        fname_con = \"banner_onset_io_tlag{:03d}_twin{:03d}_con.pkl\".format(tlag, twin)\n",
    "        fname_aki = os.path.join(fileDir, dirFrom_banner, fname_aki)\n",
    "        fname_con = os.path.join(fileDir, dirFrom_banner, fname_con)\n",
    "        io_mat_aki = pd.read_pickle(fname_aki)\n",
    "    #     if only_level:\n",
    "    #         io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_stm['ceidAKILevel']), :]\n",
    "    #     elif only_rate:\n",
    "    #         io_mat_aki = io_mat_aki.loc[np.in1d(io_mat_aki.encounter_id, ceid_group_stm['ceidAKIRate']), :]\n",
    "\n",
    "        io_mat_con = pd.read_pickle(fname_con)\n",
    "        io_mat = pd.concat([io_mat_aki, io_mat_con], axis=0)\n",
    "        for ft in io_mat.columns:\n",
    "            if 'lactic_acid' in ft:\n",
    "                io_mat[ft] = io_mat[ft]*9.009        \n",
    "            #     elif 'creatinine' in ft:\n",
    "            #         _io_onset[ft] = _io_onset[ft]*0.01131\n",
    "    #         elif 'glucose' in ft:\n",
    "    #             io_mat[ft] = io_mat[ft]*18.0182\n",
    "    #         elif 'albumin' in ft:\n",
    "    #             io_mat[ft] = io_mat[ft]*0.1\n",
    "\n",
    "\n",
    "\n",
    "    #             io_mat = stm.uomConvert('stm', 'ism', io_mat)\n",
    "\n",
    "        lr_pred = ppaki.AKI_predictor_log(io_mat, ready=False, cutoff=cut_off, fill_mode=fill_mode, \n",
    "                                          ref_type=ref_type, cv=cv, \n",
    "                                          timelag=tlag, timewindow=twin, do_balance=False)\n",
    "\n",
    "        X_train = lr_pred.X_train.as_matrix()\n",
    "        y_train = lr_pred.y_train\n",
    "        X_test = lr_pred.X_test.as_matrix()\n",
    "        y_test = lr_pred.y_test\n",
    "        predictors = lr_pred.cols        \n",
    "\n",
    "        f = open(fname_tt_pkl, 'wb')\n",
    "        pickle.dump({'X_train': X_train, \n",
    "                     'y_train': y_train, \n",
    "                     'X_test': X_test,\n",
    "                     'y_test': y_test, \n",
    "                     'predictors': predictors}, f)\n",
    "        f.close()\n",
    "\n",
    "        io.savemat(fname_tt_mat, {'X_train':X_train, 'y_train': y_train, \n",
    "                                  'X_test': X_test, 'y_test': y_test, \n",
    "                                  'predictors': predictors})\n",
    "    #         except:\n",
    "    #             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ISM-STM across-institute train-test data set (Inner join)\n",
    "> * For common predictos in both ISM and STM: no filling NaN values\n",
    "> * For missing predictors in STM: Ignored\n",
    "> * UOMs of lactic_acid, creatinine, glucose, albumin are converted to be consistent with those of  ISM UOMs\n",
    "> * ph, glucose, ratio_pao2_flo2 ignored since the distributions are different\n",
    "> * ph in STM is gastric ph whereas ph in ISM is blood ph. Gastric ph is significantly lower than blood ph.\n",
    "> * glucose in STM seems to be lower than that in ISM\n",
    "> * PF ratio in ISM and STM are not in the same dynamic range. PF ratio given in STM is not consistent\n",
    "> with PF ratio calculated by PaO2 and FiO2\n",
    "> * Class balanced\n",
    "> * Not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ex_fts = ['ph', 'glucose', 'ratio_pao2_flo2']\n",
    "# suffices = ['min', 'max', 'mean', 'median', 'last']\n",
    "# ex_fts_full = [ft+\"_\"+suff for ft in ex_fts for suff in suffices]\n",
    "\n",
    "# for tlag, twin in np.abs(combination):\n",
    "    \n",
    "# #     Check if test-train files exist\n",
    "#     fname_tt_pkl = \"across_inner_onset_tt_tlag{:03d}_twin{:03d}.pkl\".format(tlag, twin)\n",
    "#     fname_tt_pkl = os.path.join(fileDir, \"train_test_across_inner_nofill\", fname_tt_pkl)\n",
    "#     fname_tt_mat = 'across_inner_onset_tt_tlag{:03d}_twin{:03d}.mat'.format(tlag, twin)\n",
    "#     fname_tt_mat = os.path.join(fileDir, 'train_test_across_inner_nofill', fname_tt_mat)\n",
    "    \n",
    "#     if os.path.isfile(fname_tt_pkl) and os.path.isfile(fname_tt_mat):\n",
    "#         pass\n",
    "#     else:\n",
    "# #         try:\n",
    "#             fname_ism_aki = \"ism_onset_io_tlag{:03d}_twin{:03d}_aki.pkl\".format(tlag, twin)\n",
    "#             fname_ism_con = \"ism_onset_io_tlag{:03d}_twin{:03d}_con.pkl\".format(tlag, twin)\n",
    "#             fname_ism_aki = os.path.join(fileDir, \"io_ism\", fname_ism_aki)\n",
    "#             fname_ism_con = os.path.join(fileDir, \"io_ism\", fname_ism_con)\n",
    "#             io_mat_ism_aki = pd.read_pickle(fname_ism_aki)\n",
    "#             io_mat_ism_con = pd.read_pickle(fname_ism_con)\n",
    "#             io_mat_ism = pd.concat([io_mat_ism_aki, io_mat_ism_con], axis=0)\n",
    "\n",
    "#             fname_stm_aki = \"stm_onset_io_tlag{:03d}_twin{:03d}_aki.pkl\".format(tlag, twin)\n",
    "#             fname_stm_con = \"stm_onset_io_tlag{:03d}_twin{:03d}_con.pkl\".format(tlag, twin)\n",
    "#             fname_stm_aki = os.path.join(fileDir, \"io_stm\", fname_stm_aki)\n",
    "#             fname_stm_con = os.path.join(fileDir, \"io_stm\", fname_stm_con)\n",
    "#             io_mat_stm_aki = pd.read_pickle(fname_stm_aki)\n",
    "#             io_mat_stm_con = pd.read_pickle(fname_stm_con)\n",
    "#             io_mat_stm = pd.concat([io_mat_stm_aki, io_mat_stm_con], axis=0)\n",
    "#             io_mat_stm = stm.uomConvert('stm', 'ism', io_mat_stm)\n",
    "\n",
    "#             io_mat = pd.concat([io_mat_ism, io_mat_stm], axis=0, join='inner')\n",
    "#             valcol = [col for col in io_mat.columns if col not in ex_fts_full]\n",
    "#             io_mat = io_mat.loc[:, valcol]\n",
    "\n",
    "#             lr_pred = ppaki.AKI_predictor_log(io_mat, ready=False, cutoff=cut_off, fill_mode=fill_mode,\n",
    "#                                               ref_type=ref_type, cv=cv, \n",
    "#                                               timelag=tlag, timewindow=twin)\n",
    "\n",
    "#             X_train = lr_pred.X_train.as_matrix()\n",
    "#             y_train = lr_pred.y_train\n",
    "#             X_test = lr_pred.X_test.as_matrix()\n",
    "#             y_test = lr_pred.y_test\n",
    "#             predictors = lr_pred.cols\n",
    "\n",
    "#             f = open(fname_tt_pkl, 'wb')\n",
    "#             pickle.dump({'X_train': X_train, \n",
    "#                          'y_train': y_train, \n",
    "#                          'X_test': X_test,\n",
    "#                          'y_test': y_test, \n",
    "#                          'predictors': predictors}, f)\n",
    "#             f.close()\n",
    "\n",
    "#             io.savemat(fname_tt_mat, {'X_train':X_train, 'y_train': y_train, \n",
    "#                                    'X_test': X_test, 'y_test': y_test, \n",
    "#                                    'predictors': predictors})\n",
    "# #         except:\n",
    "# #             pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

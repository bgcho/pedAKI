{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add composite variabels (SI, OSI, OI) to I/O dataframe for STM\n",
    "* Query or load the dataframes that are required to to calculate the composite variables\n",
    "* Calculate the composite variabels\n",
    "* Add he composite variables to the original I/O dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stm_utilities as stm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "stmdb = stm.queryDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def queryDF4composites(encounter_ids, stm_instance=None,\n",
    "                       hr_df=None, nsbp_df=None,\n",
    "                       map_df=None, fio2_df=None,\n",
    "                       spo2_df=None, pao2_df=None):\n",
    "\n",
    "    try:\n",
    "        if hr_df is None:\n",
    "            hr_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_hr_df.pkl'))\n",
    "        hr_df = hr_df.loc[np.in1d(hr_df.encounter_id, encounter_ids),:]\n",
    "    except:\n",
    "        hr_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                     feature_ids={'attr_concept_code': [364075005],\n",
    "                                                  'intv_concept_code': [364075005]})\n",
    "#     print('hr dataframe queried ..')\n",
    "\n",
    "    try:\n",
    "        if nsbp_df is None:\n",
    "            nsbp_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_nsbp_df.pkl'))\n",
    "        nsbp_df = nsbp_df.loc[np.in1d(nsbp_df.encounter_id, encounter_ids), :]\n",
    "    except:\n",
    "        nsbp_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                       feature_ids={'attr_concept_code': [271649006],\n",
    "                                                    'intv_concept_code': [17146006]})\n",
    "#     print('nsbp dataframe queried ..')\n",
    "\n",
    "    try:\n",
    "        if map_df is None:\n",
    "            map_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_map_df.pkl'))\n",
    "        map_df = map_df.loc[np.in1d(map_df.encounter_id, encounter_ids), :]\n",
    "    except:\n",
    "        map_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                      feature_ids={'attr_concept_code': [259010008],\n",
    "                                                   'intv_concept_code': [284019003]})\n",
    "#     print('map dataframe queried ..')\n",
    "\n",
    "    try:\n",
    "        if fio2_df is None:\n",
    "            fio2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_fio2_df.pkl'))\n",
    "        fio2_df = fio2_df.loc[np.in1d(fio2_df.encounter_id, encounter_ids), :]\n",
    "    except:\n",
    "        fio2_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                       feature_ids={'attr_concept_code': [250774007],\n",
    "                                                    'intv_concept_code': [250774007]})\n",
    "#     print('fio2 dataframe queried ..')\n",
    "\n",
    "    try:\n",
    "        if spo2_df is None:\n",
    "            spo2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_spo2_df.pkl'))\n",
    "        spo2_df = spo2_df.loc[np.in1d(spo2_df.encounter_id, encounter_ids),:]\n",
    "    except:\n",
    "        spo2_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                       feature_ids={'attr_concept_code': [250554003],\n",
    "                                                    'intv_concept_code': [250554003]})\n",
    "#     print('spo2 dataframe queried ..')\n",
    "\n",
    "    try:\n",
    "        if pao2_df is None:\n",
    "            pao2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_pao2_df.pkl'))\n",
    "        pao2_df = pao2_df.loc[np.in1d(pao2_df.encounter_id, encounter_ids), :]\n",
    "    except:\n",
    "        pao2_df = stmdb.getFeatureData(encounter_ids=encounter_ids,\n",
    "                                       feature_ids={'attr_concept_code': [250546000],\n",
    "                                                    'intv_concept_code': [250546000]})\n",
    "#     print('pao2 dataframe queried ..')\n",
    "    \n",
    "    return hr_df, nsbp_df, map_df, fio2_df, spo2_df, pao2_df\n",
    "\n",
    "def filtObservation(item_df, scr_df, timelag, timewin):\n",
    "    enc_reft = scr_df.groupby('encounter_id')['reftime'].unique().to_frame()\n",
    "    enc_reft = enc_reft.reset_index()\n",
    "    enc_reft['reftime'] = np.hstack(enc_reft.reftime)\n",
    "    \n",
    "#     item_df = item_df.merge(scr_df.loc[:, ['encounter_id', 'reftime']], on='encounter_id', how='inner')\n",
    "    item_df = item_df.merge(enc_reft, on='encounter_id', how='inner')\n",
    "    item_df.rename(columns={'tstamp': 'charttime'}, inplace=True)\n",
    "    if timelag > 0:\n",
    "        item_df['fromtime'] = item_df.reftime\n",
    "        item_df['totime'] = item_df.reftime + np.timedelta64(int(timelag * 60), 'm')\n",
    "        # time_mask = (_df.charttime > _df.reftime) & (_df.charttime < _df.totime)\n",
    "    else:\n",
    "        item_df['fromtime'] = item_df.reftime + np.timedelta64(int(timelag * 60), 'm')\n",
    "        item_df['totime'] = item_df.reftime + np.timedelta64(int((timelag + timewin) * 60), 'm')\n",
    "    time_mask = (item_df.charttime > item_df.fromtime) & (item_df.charttime < item_df.totime)\n",
    "    item_df = item_df.loc[time_mask, :]\n",
    "    \n",
    "    return item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertMapUOM(map_df):\n",
    "    if map_df.valueUOM.unique()[0] == 'mmHg':\n",
    "        map_df.value = map_df.value*float(1.36)\n",
    "        map_df.valueUOM = 'cmH2O'\n",
    "    return map_df\n",
    "\n",
    "def convertFio2UOM(fio2_df):\n",
    "    if fio2_df.valueUOM.unique()[0] == '%':\n",
    "        fio2_df.value = fio2_df.value*0.01\n",
    "        fio2_df.valueUOM = 'fraction'\n",
    "    return fio2_df\n",
    "\n",
    "def convertPao2UOM(pao2_df):\n",
    "    if pao2_df.valueUOM.unique()[0] == 'kPa':\n",
    "        pao2_df.value = pao2_df.value*7.5006\n",
    "        pao2_df.valueUOM = 'mmHg'\n",
    "    return pao2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# si_df_filtered = hr_df_filtered.groupby('encounter_id').apply(getSI, nsbp_df_filtered)\n",
    "# si_df_filtered = si_df_filtered.loc[:, ['encounter_id', 'charttime', 'reftime', 'fromtime', 'totime', 'si']]\n",
    "# si_df_filtered.rename(columns={'si':'value'}, inplace=True)\n",
    "# si_df_filtered['valueUOM'] = 'bpm/mmHg'\n",
    "\n",
    "def getSI(hr_df_group, nsbp_df_filtered):\n",
    "    nsbp_df_group = nsbp_df_filtered.loc[nsbp_df_filtered.encounter_id\n",
    "                                         ==hr_df_group.encounter_id.unique()[0], :]\n",
    "    hr_df_group['si'] = np.nan\n",
    "    tdiff = np.timedelta64(60, 'm')\n",
    "    if not nsbp_df_group.empty:\n",
    "        for idx, row in hr_df_group.iterrows():\n",
    "            idxmin = abs(nsbp_df_group.charttime-row.charttime).idxmin()\n",
    "            valmin = abs(nsbp_df_group.charttime-row.charttime).min()\n",
    "            \n",
    "            if valmin<=np.timedelta64(60,'m'):\n",
    "                try:\n",
    "                    hr_df_group.si[idx] = row.value/float(nsbp_df_group.value[idxmin])\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return hr_df_group\n",
    "\n",
    "def getSIDF(hr_df, nsbp_df):\n",
    "    si_df = hr_df.groupby('encounter_id').apply(getSI, nsbp_df)\n",
    "    si_df = si_df.loc[:, ['encounter_id', 'charttime', 'reftime', 'fromtime', 'totime', 'si']]\n",
    "    si_df.rename(columns={'si':'value'}, inplace=True)\n",
    "    si_df['valueUOM'] = 'bpm/mmHg'\n",
    "    si_df = si_df.replace([np.inf, -np.inf], np.nan)\n",
    "    return si_df\n",
    "    \n",
    "def getOSI(spo2_df_group, map_df_filtered, fio2_df_filtered):\n",
    "    map_df_group = map_df_filtered.loc[map_df_filtered.encounter_id\n",
    "                                       ==spo2_df_group.encounter_id.unique()[0], :]\n",
    "    fio2_df_group = fio2_df_filtered.loc[fio2_df_filtered.encounter_id\n",
    "                                         ==spo2_df_group.encounter_id.unique()[0], :]\n",
    "    spo2_df_group['osi'] = np.nan\n",
    "    tdiff = np.timedelta64(60, 'm')\n",
    "    if not (map_df_group.empty or fio2_df_group.empty):\n",
    "        for idx, row in spo2_df_group.iterrows():\n",
    "            idxmin_map = abs(map_df_group.charttime-row.charttime).idxmin()\n",
    "            valmin_map = abs(map_df_group.charttime-row.charttime).min()\n",
    "            idxmin_fio2 = abs(fio2_df_group.charttime-row.charttime).idxmin()\n",
    "            valmin_fio2 = abs(fio2_df_group.charttime-row.charttime).min()\n",
    "            \n",
    "            if (valmin_map<=np.timedelta64(60,'m')) and (valmin_fio2<=np.timedelta64(60,'m')):\n",
    "                try:\n",
    "                    spo2_df_group.osi[idx] = (map_df_group.value[idxmin_map]\n",
    "                                              *fio2_df_group.value[idxmin_fio2]*100)/float(row.value)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return spo2_df_group\n",
    "\n",
    "def getOSIDF(spo2_df, map_df, fio2_df):\n",
    "    osi_df = spo2_df.groupby('encounter_id').apply(getOSI, map_df, fio2_df)\n",
    "    osi_df = osi_df.loc[:, ['encounter_id', 'charttime', 'reftime', 'fromtime', 'totime', 'osi']]\n",
    "    osi_df.rename(columns={'osi':'value'}, inplace=True)\n",
    "    osi_df['valueUOM'] = 'cmH2O'\n",
    "    osi_df = osi_df.replace([np.inf, -np.inf], np.nan)\n",
    "    return osi_df\n",
    "\n",
    "def getOI(pao2_df_group, map_df_filtered, fio2_df_filtered):\n",
    "    map_df_group = map_df_filtered.loc[map_df_filtered.encounter_id\n",
    "                                       ==pao2_df_group.encounter_id.unique()[0], :]\n",
    "    fio2_df_group = fio2_df_filtered.loc[fio2_df_filtered.encounter_id\n",
    "                                         ==pao2_df_group.encounter_id.unique()[0], :]\n",
    "    pao2_df_group['oi'] = np.nan\n",
    "    tdiff = np.timedelta64(60, 'm')\n",
    "    if not (map_df_group.empty or fio2_df_group.empty):\n",
    "        for idx, row in pao2_df_group.iterrows():\n",
    "            idxmin_map = abs(map_df_group.charttime-row.charttime).idxmin()\n",
    "            valmin_map = abs(map_df_group.charttime-row.charttime).min()\n",
    "            idxmin_fio2 = abs(fio2_df_group.charttime-row.charttime).idxmin()\n",
    "            valmin_fio2 = abs(fio2_df_group.charttime-row.charttime).min()\n",
    "            \n",
    "            if (valmin_map<=np.timedelta64(60,'m')) and (valmin_fio2<=np.timedelta64(60,'m')):\n",
    "                try:\n",
    "                    pao2_df_group.oi[idx] = (map_df_group.value[idxmin_map]\n",
    "                                             *fio2_df_group.value[idxmin_fio2]*100)/(row.value*1.36)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return pao2_df_group\n",
    "\n",
    "def getOIDF(pao2_df, map_df, fio2_df):\n",
    "    oi_df = pao2_df.groupby('encounter_id').apply(getOI, map_df, fio2_df)\n",
    "    oi_df = oi_df.loc[:, ['encounter_id', 'charttime', 'reftime', 'fromtime', 'totime', 'oi']]\n",
    "    oi_df.rename(columns={'oi':'value'}, inplace=True)\n",
    "    oi_df['valueUOM'] = '%'\n",
    "    oi_df = oi_df.replace([np.inf, -np.inf], np.nan)\n",
    "    return oi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLastValDF(group):\n",
    "    \n",
    "    tmp_group = group.loc[~pd.isnull(group.value),:]\n",
    "    if not tmp_group.empty:\n",
    "        return tmp_group.value[tmp_group.charttime.idxmax()]\n",
    "    else:\n",
    "        return np.NaN\n",
    "    \n",
    "def add2IO(io_df, feature_dfs, stats):\n",
    "    feature_stats = [(feature, stat) for feature in feature_dfs for stat in stats]\n",
    "    for feature, stat in feature_stats:\n",
    "        feature_df = feature_dfs[feature]\n",
    "        ft_name = feature+'_'+stat\n",
    "#         print(ft_name)\n",
    "        if stat !='last':\n",
    "            ft_stat_df = eval(\"feature_df.groupby('encounter_id')['value'].\"+stat+\"().reset_index()\")\n",
    "        else:\n",
    "            ft_stat_sr = feature_df.groupby('encounter_id').apply(getLastValDF)\n",
    "            ft_stat_df = pd.DataFrame(ft_stat_sr)\n",
    "            ft_stat_df.rename(columns={0: 'value'}, inplace=True)\n",
    "            ft_stat_df = ft_stat_df.reset_index()\n",
    "            \n",
    "        io_df = io_df.merge(ft_stat_df, on='encounter_id', how='left')\n",
    "        io_df.rename(columns={'value': ft_name}, inplace=True)\n",
    "    return io_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(\"__file__\")\n",
    "timelag = np.arange(-6,-25,-1)\n",
    "timewin = [6, 12]\n",
    "stabletime = list([12])\n",
    "combination = [(tlag, twin, stime) for tlag in timelag for twin in timewin \n",
    "               for stime in stabletime if abs(tlag)>=twin]\n",
    "# combination = combination[16:]\n",
    "# combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timelag: -6, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -6, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -7, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -7, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -8, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -8, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -9, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -9, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -10, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -10, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -11, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -11, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -12, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -12, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -12, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -12, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -13, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -13, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -13, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -13, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -14, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -14, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -14, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -14, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -15, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -15, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -15, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -15, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -16, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -16, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -16, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -16, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -17, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -17, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -17, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -17, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -18, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -18, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -18, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -18, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -19, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -19, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -19, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -19, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -20, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -20, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -20, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -20, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -21, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -21, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -21, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -21, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -22, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -22, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -22, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -22, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -23, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -23, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -23, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -23, timewindow: 12 finished!! \n",
      "\n",
      "timelag: -24, timewindow: 6\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -24, timewindow: 6 finished!! \n",
      "\n",
      "timelag: -24, timewindow: 12\n",
      "Queried the dataframes ...\n",
      "Required dataframes filtered by observation window ...\n",
      "UOM converted ...\n",
      "Got Shock Index ...\n",
      "Got Oxygenation Saturation Index ...\n",
      "Got Oxygenation Index ...\n",
      "Added to the I/O dataframe\n",
      "timelag: -24, timewindow: 12 finished!! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(fileDir, 'io_stm2')):\n",
    "    os.makedirs(os.path.join(fileDir, 'io_stm2'))\n",
    "\n",
    "hr_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_hr_df.pkl'))\n",
    "nsbp_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_nsbp_df.pkl'))\n",
    "map_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_map_df.pkl'))\n",
    "fio2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_fio2_df.pkl'))\n",
    "spo2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_spo2_df.pkl'))\n",
    "pao2_df = pd.read_pickle(os.path.join(fileDir, 'item_df_stm', 'stm_pao2_df.pkl'))\n",
    "\n",
    "\n",
    "for tlag, twin, stime in combination:\n",
    "    print('timelag: {}, timewindow: {}'.format(tlag, twin))\n",
    "    \n",
    "    fname_scr_df = os.path.join(fileDir, 'scr_stm', \n",
    "                                'stm_onset_scr_tlag{:03d}_stime{:03d}_tot.pkl'.format(abs(tlag), stime))\n",
    "    fname_io_df_aki = os.path.join(fileDir, 'io_stm', \n",
    "                                   'stm_onset_io_tlag{:03d}_twin{:03d}_aki.pkl'.format(abs(tlag), twin))\n",
    "    fname_io_df_con = os.path.join(fileDir, 'io_stm', \n",
    "                                   'stm_onset_io_tlag{:03d}_twin{:03d}_con.pkl'.format(abs(tlag), twin))\n",
    "    \n",
    "    # Tag reference time to the creatinine dataframe\n",
    "    scr_df = pd.read_pickle(fname_scr_df)\n",
    "    if 'reftime' not in scr_df.columns:\n",
    "        scr_df = stmdb.getScrDF(pre_scr_df=scr_df, ex_age=True, ex_los=True, \n",
    "                                ex_aki_adm=True, aki_adm_hr=12, enc_per_pat=True)\n",
    "        scr_df.to_pickle(fname_scr_df)\n",
    "    \n",
    "    # Load I/O matrix\n",
    "    io_df_aki = pd.read_pickle(fname_io_df_aki)\n",
    "    io_df_con = pd.read_pickle(fname_io_df_con)\n",
    "    \n",
    "    # Query dataframes to calculate the composite predictors\n",
    "    encounter_ids_aki = io_df_aki.encounter_id.unique()\n",
    "    encounter_ids_con = io_df_con.encounter_id.unique()\n",
    "    \n",
    "    (hr_df_aki, nsbp_df_aki, map_df_aki, \n",
    "     fio2_df_aki, spo2_df_aki, pao2_df_aki) = queryDF4composites(encounter_ids_aki,\n",
    "                                                                 hr_df=hr_df, nsbp_df=nsbp_df,\n",
    "                                                                 map_df=map_df, fio2_df=fio2_df, \n",
    "                                                                 spo2_df=spo2_df, pao2_df=pao2_df)\n",
    "    (hr_df_con, nsbp_df_con, map_df_con, \n",
    "     fio2_df_con, spo2_df_con, pao2_df_con) = queryDF4composites(encounter_ids_con,\n",
    "                                                                 hr_df=hr_df, nsbp_df=nsbp_df, \n",
    "                                                                 map_df=map_df, fio2_df=fio2_df, \n",
    "                                                                 spo2_df=spo2_df, pao2_df=pao2_df)\n",
    "    print('Queried the dataframes ...')\n",
    "    \n",
    "    # Filter dataframes with the observation window\n",
    "    hr_df_filtered_aki = filtObservation(hr_df_aki, scr_df, tlag, twin)\n",
    "    nsbp_df_filtered_aki = filtObservation(nsbp_df_aki, scr_df, tlag, twin)\n",
    "    map_df_filtered_aki = filtObservation(map_df_aki, scr_df, tlag, twin)\n",
    "    fio2_df_filtered_aki = filtObservation(fio2_df_aki, scr_df, tlag, twin)\n",
    "    spo2_df_filtered_aki = filtObservation(spo2_df_aki, scr_df, tlag, twin)\n",
    "    pao2_df_filtered_aki = filtObservation(pao2_df_aki, scr_df, tlag, twin)\n",
    "    \n",
    "    hr_df_filtered_con = filtObservation(hr_df_con, scr_df, tlag, twin)\n",
    "    nsbp_df_filtered_con = filtObservation(nsbp_df_con, scr_df, tlag, twin)\n",
    "    map_df_filtered_con = filtObservation(map_df_con, scr_df, tlag, twin)\n",
    "    fio2_df_filtered_con = filtObservation(fio2_df_con, scr_df, tlag, twin)\n",
    "    spo2_df_filtered_con = filtObservation(spo2_df_con, scr_df, tlag, twin)\n",
    "    pao2_df_filtered_con = filtObservation(pao2_df_con, scr_df, tlag, twin)\n",
    "    print('Required dataframes filtered by observation window ...')\n",
    "    \n",
    "    # Convert UOM to be consistent with ISM\n",
    "    map_df_filtered_aki = convertMapUOM(map_df_filtered_aki)\n",
    "    map_df_filtered_con = convertMapUOM(map_df_filtered_con)\n",
    "    \n",
    "    fio2_df_filtered_aki = convertFio2UOM(fio2_df_filtered_aki)\n",
    "    fio2_df_filtered_con = convertFio2UOM(fio2_df_filtered_con)\n",
    "    \n",
    "    pao2_df_filtered_aki = convertPao2UOM(pao2_df_filtered_aki)\n",
    "    pao2_df_filtered_con = convertPao2UOM(pao2_df_filtered_con)\n",
    "    print('UOM converted ...')\n",
    "    \n",
    "    # Get Shock index (SI) dataframe\n",
    "    si_df_filtered_aki = getSIDF(hr_df_filtered_aki, nsbp_df_filtered_aki)\n",
    "    si_df_filtered_con = getSIDF(hr_df_filtered_con, nsbp_df_filtered_con)\n",
    "    print('Got Shock Index ...')\n",
    "    \n",
    "    # Get Oxygenation Saturation Index (OSI) dataframe\n",
    "    osi_df_filtered_aki = getOSIDF(spo2_df_filtered_aki, map_df_filtered_aki, \n",
    "                                   fio2_df_filtered_aki)\n",
    "    osi_df_filtered_con = getOSIDF(spo2_df_filtered_con, map_df_filtered_con, \n",
    "                                   fio2_df_filtered_con)\n",
    "    print('Got Oxygenation Saturation Index ...')\n",
    "    \n",
    "    # Get Oxygenation Index (OI) dataframe\n",
    "    oi_df_filtered_aki = getOIDF(pao2_df_filtered_aki, map_df_filtered_aki,\n",
    "                                 fio2_df_filtered_aki)\n",
    "    oi_df_filtered_con = getOIDF(pao2_df_filtered_con, map_df_filtered_con,\n",
    "                                 fio2_df_filtered_con)\n",
    "    print('Got Oxygenation Index ...')\n",
    "    \n",
    "    # Add feature statistics to the I/O dataframe\n",
    "    feature_dfs_aki = {'si': si_df_filtered_aki, 'osi': osi_df_filtered_aki, 'oi': oi_df_filtered_aki}\n",
    "    feature_dfs_con = {'si': si_df_filtered_con, 'osi': osi_df_filtered_con, 'oi': oi_df_filtered_con}\n",
    "    stats = ['min', 'max', 'mean', 'last', 'median']\n",
    "    \n",
    "    io_df_full_aki = add2IO(io_df_aki, feature_dfs_aki, stats)\n",
    "    io_df_full_con = add2IO(io_df_con, feature_dfs_con, stats)\n",
    "    print('Added to the I/O dataframe')    \n",
    "    \n",
    "    fname_io_full_aki2 = os.path.join(fileDir, 'io_stm2', \n",
    "                                      'stm_onset_io_tlag{:03d}_twin{:03d}_aki.pkl'.format(abs(tlag), twin))\n",
    "    fname_io_full_con2 = os.path.join(fileDir, 'io_stm2', \n",
    "                                      'stm_onset_io_tlag{:03d}_twin{:03d}_con.pkl'.format(abs(tlag), twin))\n",
    "    io_df_full_aki.to_pickle(fname_io_full_aki2)\n",
    "    io_df_full_con.to_pickle(fname_io_full_con2)\n",
    "    \n",
    "    print('timelag: {}, timewindow: {} finished!! \\n'.format(tlag, twin))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag reference time to the creatinine dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous I/O matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# io_df_aki = pd.read_pickle(fname_io_df_aki)\n",
    "# io_df_con = pd.read_pickle(fname_io_df_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hr_df_filtered = filtObservation(hr_df, scr_df, timelag, timewin)\n",
    "# nsbp_df_filtered = filtObservation(nsbp_df, scr_df, timelag, timewin)\n",
    "# map_df_filtered = filtObservation(map_df, scr_df, timelag, timewin)\n",
    "# fio2_df_filtered = filtObservation(fio2_df, scr_df, timelag, timewin)\n",
    "# spo2_df_filtered = filtObservation(spo2_df, scr_df, timelag, timewin)\n",
    "# pao2_df_filtered = filtObservation(pao2_df, scr_df, timelag, timewin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(pao2_df_filtered.valueUOM.unique()[0])\n",
    "# print(fio2_df_filtered.valueUOM.unique()[0])\n",
    "# print(map_df_filtered.valueUOM.unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# si_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# osi_df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# oi_df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# oi_df_filtered.groupby('encounter_id')['value'].mean().reset_index().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature_dfs = {'si': si_df_filtered, 'osi': osi_df_filtered, 'oi': oi_df_filtered}\n",
    "# stats = ['min', 'max', 'mean', 'last', 'median']\n",
    "# feature_stats = [(feature, stat) for feature in feature_dfs for stat in stats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# io_df_full_aki = add2IO(io_df_aki, feature_dfs, stats)\n",
    "# io_df_full_con = add2IO(io_df_con, feature_dfs, stats)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

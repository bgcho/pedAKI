{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to query Each items from BANNER db\n",
    "* Running this piece of code before starting the analysis significantly reduces the time consuming querying process.\n",
    "* This script qeuries the BANNER dB for each feature. (Not filtered by list of encounters of interest.)\n",
    "* Then saves each dataframe in a designated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname('__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_df = pd.read_csv(os.path.join(fileDir, 'csv_banner', 'Banner_encounters.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parDir = os.path.join(fileDir, 'BannerData_pandas', '160701_no_strings_has_duplicates')\n",
    "pdDirs = [x[0] for x in os.walk(parDir)]\n",
    "pdDirs = pdDirs[1:]\n",
    "\n",
    "f_dfs = list()\n",
    "for pdDir in pdDirs:\n",
    "    f_df = [x[2] for x in os.walk(pdDir)]\n",
    "    f_df = [os.path.join(pdDir, f) for f in f_df[0]]\n",
    "    f_dfs.extend(f_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Below cell is to concatenate the 1026 chartevent tables into 11 chart event tables. **\n",
    "* This is to reduce the time loading each table for querying each feature (item)\n",
    "* Run the below cell only when you haven't created 11 concatenated chart event tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cell = False\n",
    "\n",
    "def concatDF(f_dfs):\n",
    "    chart_df = pd.DataFrame()\n",
    "    for f_df in f_dfs:\n",
    "#         print('Loading {}'.format(f_df))\n",
    "        ban_df = pd.read_pickle(f_df)\n",
    "        ban_df = convertDtype(ban_df)\n",
    "        chart_df = pd.concat([chart_df, ban_df], axis=0)\n",
    "        \n",
    "    print('Chart DF number of rows: {}'.format(len(chart_df.index)))\n",
    "    return chart_df\n",
    "\n",
    "if run_cell:\n",
    "    stump_size = 100\n",
    "    idx_group = np.arange(0, len(f_dfs), stump_size)\n",
    "    idx_group = np.append(idx_group, len(f_dfs))\n",
    "\n",
    "    f_group = list()\n",
    "    for idx_start, idx_end in zip(idx_group[:-1], idx_group[1:]):\n",
    "        f_group.append(f_dfs[idx_start:idx_end])\n",
    "\n",
    "    f_name = os.path.join(fileDir, 'BannerData_pandas', 'chart_df')\n",
    "    count = 0\n",
    "    for files in f_group:\n",
    "        f_name_full = f_name+'{:02d}'.format(count)+'.pkl'\n",
    "        count +=1\n",
    "        chart_df = concatDF(files)\n",
    "        chart_df.to_pickle(f_name_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Below cell is to find the item_id for each feature **\n",
    "* Skip this cell if not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertDtype(ban_df):\n",
    "    ban_df.EVENT_CD = pd.to_numeric(ban_df.EVENT_CD)\n",
    "    ban_df.RESULT_UNITS_CD = pd.to_numeric(ban_df.RESULT_UNITS_CD)\n",
    "    return ban_df\n",
    "\n",
    "def getItemID(ban_df):\n",
    "    item_id = ban_df.groupby('EVENT_CD')['EVENT_NAME'].unique().to_frame().reset_index()\n",
    "    item_id.EVENT_NAME = np.hstack(item_id.EVENT_NAME)\n",
    "    return item_id\n",
    "\n",
    "import re\n",
    "def findPattern(item_id, pattern):\n",
    "#     pattern = re.compile(\"[Hh]emo\")\n",
    "    match = {row.EVENT_CD: row.EVENT_NAME for idx, row in item_id.iterrows() \n",
    "             if pattern.match(row.EVENT_NAME) is not None}\n",
    "    return match\n",
    "\n",
    "fBig = os.path.join(fileDir, 'BannerData_pandas', 'chart_df00.pkl')\n",
    "chartBig_df = pd.read_pickle(fBig)\n",
    "item_name = getItemID(chartBig_df)\n",
    "\n",
    "# feature = 'glucose'\n",
    "# pattern = re.compile('.*[gG]lucose')\n",
    "# feature = 'albumin'\n",
    "# pattern = re.compile('.*[aA]lbumin')\n",
    "# feature = 'bilirubin'\n",
    "# pattern = re.compile('.*[bB]ilirubin')\n",
    "# feature = 'bun'\n",
    "# pattern = re.compile('.*[bB][uU][nN]$')\n",
    "# feature = 'calcium'\n",
    "# pattern = re.compile('[cC]alcium$')\n",
    "# feature = 'creatinine'\n",
    "# pattern = re.compile('.*[cC]reatinine$')\n",
    "# feature = 'fio2'\n",
    "# pattern = re.compile('.*[fF][iI][oO]2$')\n",
    "# feature = 'hemoglobin'\n",
    "# pattern = re.compile('.*[hH][eE][mM][oO][gG][lL][oO][bB][iI][nN]')\n",
    "# feature = 'hr'\n",
    "# pattern = re.compile('Heart Rate$')\n",
    "feature = 'lactic_acid'\n",
    "pattern = re.compile('[lL]actic [aA]cid')\n",
    "feature = 'pao2'\n",
    "pattern = re.compile('[pP][oO]2')\n",
    "match = findPattern(item_name, pattern)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_id_ban = {'albumin': [705919],\n",
    "               'creatinine': [681994],\n",
    "               'fio2': [3053636, 826661], \n",
    "               'glucose': [15616636], \n",
    "               'hemoglobin': [3158492, 463628023], \n",
    "               'hr': [3049471], \n",
    "               'lactic_acid': [705954,9792755,133416203,245357455,981787332,9792756],\n",
    "               'map': [100136725, 3049686], \n",
    "               'ndbp': [3059689], \n",
    "               'nsbp': [3059679], \n",
    "               'pao2': [120802110, 15616657, 1035600271], \n",
    "               'ph': [15616654,15616653,3158213,706018,120802108],\n",
    "               'platelet': [682006], \n",
    "               'potassium': [681988], \n",
    "               'ratio_pao2_flo2': None,\n",
    "               'sao2': [3053467], \n",
    "               'spo2': [3053467],\n",
    "               'temperature': [3144901], \n",
    "               'urine': [3141699,3130213,463812828,3106998,684010,3141701],\n",
    "               'wbc': [681997], \n",
    "               'bun': [681993],\n",
    "               'bilirubin': [705932], \n",
    "               'calcium': [681996], \n",
    "               'weight': [3053089]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pao2': [120802110, 15616657, 1035600271]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pedAKI = ['pao2']\n",
    "# item_pedAKI = ['fio2', 'hemoglobin', 'lactic_acid', 'map', 'ph', 'urine']\n",
    "\n",
    "\n",
    "# item_pedAKI = ['albumin', 'creatinine', 'fio2', 'glucose', \n",
    "#                'hemoglobin', 'hr', 'lactic_acid', 'map', \n",
    "#                'ndbp', 'nsbp', 'pao2', 'ph', 'platelet', 'potassium', \n",
    "#                'sao2', 'spo2', 'temperature', 'urine', 'wbc',\n",
    "#                'bun', 'bilirubin', 'calcium', 'weight']\n",
    "item_dic_pedAKI = {item: item_id_ban[item] for item in item_pedAKI}\n",
    "item_dic_pedAKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getItemDF(item_id):    \n",
    "    item_df = pd.DataFrame()\n",
    "    sfx_all = range(11)\n",
    "    for sfx in sfx_all:\n",
    "        fname = 'chart_df{:02d}.pkl'.format(sfx)\n",
    "        fname = os.path.join(fileDir, 'BannerData_pandas', fname)\n",
    "        chart_df = pd.read_pickle(fname)\n",
    "        chart_df = convertDtype(chart_df)\n",
    "        item_df_sub = chart_df.loc[np.in1d(chart_df.EVENT_CD, item_id),:]        \n",
    "        item_df = pd.concat([item_df, item_df_sub], axis=0)\n",
    "    return item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying pao2\n",
      "Queried pao2\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(fileDir, 'item_df_banner')):\n",
    "        os.makedirs(os.path.join(fileDir, 'item_df_banner'))\n",
    "        \n",
    "for item in item_dic_pedAKI:\n",
    "    item_id = item_dic_pedAKI[item]\n",
    "    fname = os.path.join(fileDir, 'item_df_banner', 'banner_{}_df.pkl'.format(item))\n",
    "    if not os.path.exists(fname):\n",
    "        print('Querying {}'.format(item))\n",
    "        item_df = getItemDF(item_id)\n",
    "        item_df.to_pickle(fname)\n",
    "        print('Queried {}'.format(item))\n",
    "#         print(item_df.head())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
